{
  "hash": "bfc4358b3862791ba06363123de2edac",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"MetricDefine\"\n---\n\n# MetricDefine\n\n`MetricDefine` is the core class for defining metrics in the polars-eval-metrics framework. \nThis guide shows you how to define both simple and complex metrics for model evaluation.\n\n## Setup\n\n::: {#f0446d48 .cell execution_count=1}\n``` {.python .cell-code}\nimport sys\nsys.path.append('../src')\n\nimport polars as pl \n\nfrom polars_eval_metrics import MetricDefine\n```\n:::\n\n\n## Getting Started: A Simple MAE Metric\n\nLet's start with the simplest possible metric definition - Mean Absolute Error (MAE). This example demonstrates how to define a metric using Polars expressions for lazy evaluation.\n\n::: {#fcc9cb0e .cell execution_count=2}\n``` {.python .cell-code}\nMetricDefine(name=\"mae\")\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\nMetricDefine(name='mae', type=across_sample)\n  Label: 'mae'\n  Across-entity expression:\n    - [mae] col(\"absolute_error\").mean().alias(\"value\")\n\n(\n  pl.LazyFrame\n  .select(col(\"absolute_error\").mean().alias(\"value\"))\n)\n```\n:::\n:::\n\n\n### Understanding the Output\n\n1. **Basic Information**:\n   - `name='mae'`: The metric identifier used to reference this metric\n   - `type=across_sample`: The default aggregation type that computes across all samples\n   - `Label: 'mae'`: The display label (automatically derived from the name)\n\n2. **Summary Expression**:\n   - `[mae] col(\"absolute_error\").mean().alias(\"value\")`: The actual Polars expression\n   - `[mae]` indicates this uses the built-in MAE formula\n   - The expression calculates the mean of the `absolute_error` column\n\n3. **Polars LazyFrame Chain**:\n   - Shows the exact operations that will be executed\n   - For `across_sample` metrics, it's a simple `.select()` operation\n   - This enables efficient lazy evaluation\n\n## Available Built-in Metrics\n\nThe framework provides many common metrics out of the box. Here's the complete list:\n\n> please note the built-in expression will be stored into a `value` column by default. \n\n::: {#6c00d292 .cell execution_count=3}\n``` {.python .cell-code code-fold=\"true\"}\nfrom polars_eval_metrics import MetricRegistry\n\npl.Config.set_fmt_str_lengths(200)\n\n# Access built-in metrics from the global registry\n\n# Create a Polars DataFrame of built-in metrics\nmetrics_data = [\n    {\"name\": name, \"expression\": str(MetricRegistry.get_metric(name))} \n    for name in sorted(MetricRegistry.list_metrics())\n]\nmetrics_df = pl.DataFrame(metrics_data)\nmetrics_df\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (15, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>expression</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;mae&quot;</td><td>&quot;col(&quot;absolute_error&quot;).mean().alias(&quot;value&quot;)&quot;</td></tr><tr><td>&quot;mape&quot;</td><td>&quot;col(&quot;absolute_percent_error&quot;).mean().alias(&quot;value&quot;)&quot;</td></tr><tr><td>&quot;me&quot;</td><td>&quot;col(&quot;error&quot;).mean().alias(&quot;value&quot;)&quot;</td></tr><tr><td>&quot;mpe&quot;</td><td>&quot;col(&quot;percent_error&quot;).mean().alias(&quot;value&quot;)&quot;</td></tr><tr><td>&quot;mse&quot;</td><td>&quot;col(&quot;squared_error&quot;).mean().alias(&quot;value&quot;)&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;n_visit_with_data&quot;</td><td>&quot;col(&quot;subject_id&quot;).as_struct([col(&quot;visit_id&quot;)]).filter(col(&quot;error&quot;).is_not_null()).n_unique().alias(&quot;value&quot;)&quot;</td></tr><tr><td>&quot;pct_sample_with_data&quot;</td><td>&quot;[(col(&quot;error&quot;).is_not_null().mean()) * (dyn int: 100)].alias(&quot;value&quot;)&quot;</td></tr><tr><td>&quot;pct_subject_with_data&quot;</td><td>&quot;[([(col(&quot;subject_id&quot;).filter(col(&quot;error&quot;).is_not_null()).n_unique()) / (col(&quot;subject_id&quot;).n_unique())]) * (dyn int: 100)].alias(&quot;value&quot;)&quot;</td></tr><tr><td>&quot;pct_visit_with_data&quot;</td><td>&quot;[([(col(&quot;subject_id&quot;).as_struct([col(&quot;visit_id&quot;)]).filter(col(&quot;error&quot;).is_not_null()).n_unique()) / (col(&quot;subject_id&quot;).as_struct([col(&quot;visit_id&quot;)]).n_unique())]) * (dyn int: 100)].alias(&quot;value&quot;)&quot;</td></tr><tr><td>&quot;rmse&quot;</td><td>&quot;col(&quot;squared_error&quot;).mean().sqrt().alias(&quot;value&quot;)&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Hierarchical Aggregation\n\nSometimes you need to calculate metrics at multiple levels. For example, you might want to:\n1. Calculate MAE for each subject individually\n2. Then take the average across all subjects\n\nThis two-level aggregation respects the hierarchical structure of your data and can provide different insights than calculating metrics across all samples directly.\n\n### Using the Colon Convention\n\nFor built-in metrics, you can specify two-level aggregation using the colon (`:`) convention:\n- Format: `\"metric_name:summary_name\"`\n- Example: `\"mae:mean\"` calculates MAE per subject, then takes the mean\n\n### Example: Subject-Level MAE\n\n::: {#80fbaee6 .cell execution_count=4}\n``` {.python .cell-code}\n# Calculate MAE within each subject, then average across subjects\nMetricDefine(name=\"mae:mean\", type=\"across_subject\")\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nMetricDefine(name='mae:mean', type=across_subject)\n  Label: 'mae:mean'\n  Within-entity expressions:\n    - [mae] col(\"absolute_error\").mean().alias(\"value\")\n  Across-entity expression:\n    - [mean] col(\"value\").mean()\n\n(\n  pl.LazyFrame\n  .group_by('subject_id')\n  .agg(col(\"absolute_error\").mean().alias(\"value\"))\n  .select(col(\"value\").mean())\n)\n```\n:::\n:::\n\n\nNotice how the output now shows both aggregation levels:\n\n1. **Aggregation Expression** `[mae] col(\"absolute_error\").mean().alias(\"value\")`:\n   - **First level**: Calculates MAE within each subject group\n   - The `[mae]` tag shows this uses the built-in MAE formula\n\n2. **Summary Expression** `[mean] col(\"value\").mean()`:\n   - **Second level**: Averages the per-subject MAE values\n   - The `[mean]` tag shows this uses the built-in mean summary\n\n3. **Polars LazyFrame Chain**:\n\n```python\n.group_by('subject_id')      # Step 1: Group data by subject\n.agg(...)                    # Step 2: Calculate for each subject\n.select(...)                 # Step 3: Average across all subjects\n```\n\nThis two-level pattern is particularly useful in clinical trials, longitudinal studies, or any analysis where you need to respect the hierarchical structure of your data.\n\n## Built-in Summaries\n\nSummaries are used in the second level of hierarchical aggregation. They define how to combine the first-level results:\n\n::: {#a9caf987 .cell execution_count=5}\n``` {.python .cell-code code-fold=\"true\"}\n# Access built-in summaries from the global registry\nsummaries_data = [\n    {\"name\": name, \"expression\": str(MetricRegistry.get_summary(name))} \n    for name in sorted(MetricRegistry.list_summaries())\n]\nsummaries_df = pl.DataFrame(summaries_data)\nsummaries_df\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (14, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>expression</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;max&quot;</td><td>&quot;col(&quot;value&quot;).max()&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>&quot;col(&quot;value&quot;).mean()&quot;</td></tr><tr><td>&quot;median&quot;</td><td>&quot;col(&quot;value&quot;).median()&quot;</td></tr><tr><td>&quot;min&quot;</td><td>&quot;col(&quot;value&quot;).min()&quot;</td></tr><tr><td>&quot;p1&quot;</td><td>&quot;col(&quot;value&quot;).quantile()&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;p95&quot;</td><td>&quot;col(&quot;value&quot;).quantile()&quot;</td></tr><tr><td>&quot;p99&quot;</td><td>&quot;col(&quot;value&quot;).quantile()&quot;</td></tr><tr><td>&quot;sqrt&quot;</td><td>&quot;col(&quot;value&quot;).sqrt()&quot;</td></tr><tr><td>&quot;std&quot;</td><td>&quot;col(&quot;value&quot;).std()&quot;</td></tr><tr><td>&quot;sum&quot;</td><td>&quot;col(&quot;value&quot;).sum()&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Custom Expressions\n\nBeyond built-in metrics, you can define custom metrics using Polars expressions. \nIt provides flexibility to customized functions.\n\n### Percentage of Accurate Predictions\n\nLet's create a custom metric that calculates the percentage of samples where the absolute error is less than 1:\n\n::: {#11a980cc .cell execution_count=6}\n``` {.python .cell-code}\nMetricDefine(\n    name=\"pct_within_1\",\n    label=\"% Predictions Within +/- 1\",\n    type=\"across_sample\",\n    across_expr=(pl.col('absolute_error') < 1).mean() * 100\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nMetricDefine(name='pct_within_1', type=across_sample)\n  Label: '% Predictions Within +/- 1'\n  Across-entity expression:\n    - [custom] [([(col(\"absolute_error\")) < (dyn int: 1)].mean()) * (dyn int: 100)]\n\n(\n  pl.LazyFrame\n  .select(((col(\"absolute_error\")) < (1).mean()) * (100))\n)\n```\n:::\n:::\n\n\n### Percentile of per Subject MAE\n\n- calculate MAE for each subject. \n- calculate 90th percentile of the MAE.\n\n::: {#41a2bdf0 .cell execution_count=7}\n``` {.python .cell-code}\nMetricDefine(\n    name=\"mae_p90_by_subject\",\n    label=\"90th Percentile of Subject MAEs\",\n    type=\"across_subject\",\n    within_expr=\"mae\",\n    across_expr=pl.col('value').quantile(0.9, interpolation=\"linear\")\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\nMetricDefine(name='mae_p90_by_subject', type=across_subject)\n  Label: '90th Percentile of Subject MAEs'\n  Within-entity expressions:\n    - [mae] col(\"absolute_error\").mean().alias(\"value\")\n  Across-entity expression:\n    - [custom] col(\"value\").quantile()\n\n(\n  pl.LazyFrame\n  .group_by('subject_id')\n  .agg(col(\"absolute_error\").mean().alias(\"value\"))\n  .select(col(\"value\").quantile())\n)\n```\n:::\n:::\n\n\nIn this example we mixed built-in metrics `mae` and \ncustomized expression. \n\n### Weighted Average of per Subject MAE\n\nFor calculating weighted averages across subjects, we need to:\n1. Calculate MAE for each subject\n2. Get the weight for each subject (e.g., sample count or custom weight)\n3. Calculate the weighted average across subjects\n\n#### Method 1: \n\n::: {#fc04e02f .cell execution_count=8}\n``` {.python .cell-code}\nMetricDefine(\n    name=\"weighted_mae\",\n    label=\"Weighted Average of Subject MAEs\",\n    type=\"across_subject\",\n    within_expr=[\n        \"mae\",  # MAE per subject (stored in 'value' column)\n        pl.col(\"weight\").mean().alias(\"avg_weight\")  # Average weight per subject\n    ],\n    across_expr=(\n        (pl.col('value') * pl.col('avg_weight')).sum() / \n        pl.col('avg_weight').sum()\n    )\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nMetricDefine(name='weighted_mae', type=across_subject)\n  Label: 'Weighted Average of Subject MAEs'\n  Within-entity expressions:\n    - [mae] col(\"absolute_error\").mean().alias(\"value\")\n    - [custom] col(\"weight\").mean().alias(\"avg_weight\")\n  Across-entity expression:\n    - [custom] [([(col(\"value\")) * (col(\"avg_weight\"))].sum()) / (col(\"avg_weight\").sum())]\n\n(\n  pl.LazyFrame\n  .group_by('subject_id')\n  .agg(\n[\n      col(\"absolute_error\").mean().alias(\"value\"),\n      col(\"weight\").mean().alias(\"avg_weight\")\n    ]\n  )\n  .select(((col(\"value\")) * (col(\"avg_weight\")).sum()) /\n      (col(\"avg_weight\").sum()))\n)\n```\n:::\n:::\n\n\n#### Method 2: Using Lambda Function\nAlternatively, we can use a user-defined function (UDF) with NumPy for the weighted average calculation:\n\n::: {#29c16db4 .cell execution_count=9}\n``` {.python .cell-code}\nimport numpy as np\n\n# Define the weighted average expression\nweighted_average = (\n    pl.struct(['value', 'avg_weight'])\n    .map_batches(\n        lambda x: pl.Series([\n            np.average(\n                x.struct.field('value'), \n                weights=x.struct.field('avg_weight')\n            )\n        ]),\n        return_dtype=pl.Float64\n    )\n)\n    \nMetricDefine(\n    name=\"weighted_mae_numpy\",\n    label=\"Weighted Average of Subject MAEs (NumPy)\",\n    type=\"across_subject\",\n    within_expr=[\n        \"mae\",  # MAE per subject (stored in 'value' column)\n        pl.col(\"weight\").mean().alias(\"avg_weight\")  # Average weight per subject\n    ],\n    across_expr=weighted_average\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nMetricDefine(name='weighted_mae_numpy', type=across_subject)\n  Label: 'Weighted Average of Subject MAEs (NumPy)'\n  Within-entity expressions:\n    - [mae] col(\"absolute_error\").mean().alias(\"value\")\n    - [custom] col(\"weight\").mean().alias(\"avg_weight\")\n  Across-entity expression:\n    - [custom] col(\"value\").as_struct([col(\"avg_weight\")]).python_udf()\n\n(\n  pl.LazyFrame\n  .group_by('subject_id')\n  .agg(\n[\n      col(\"absolute_error\").mean().alias(\"value\"),\n      col(\"weight\").mean().alias(\"avg_weight\")\n    ]\n  )\n  .select(col(\"value\").as_struct([col(\"avg_weight\")).python_udf())\n)\n```\n:::\n:::\n\n\n",
    "supporting": [
      "metric_define_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}